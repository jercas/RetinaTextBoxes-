{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from Detector.input_producer import InputProducer\n",
    "from Detector.RetinaNet import RetinaNet\n",
    "from utils.preprocess import *\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.bbox import change_box_order\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "print(\"1\")\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "#### Input pipeline\n",
    "tf.app.flags.DEFINE_integer('input_size', 608,\n",
    "                            \"\"\"Input size\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_classes', 20,\n",
    "                            \"\"\"number of classes\"\"\")\n",
    "tf.app.flags.DEFINE_float('cls_thresh', 0.5,\n",
    "                            \"\"\"thresh for class\"\"\")\n",
    "tf.app.flags.DEFINE_float('nms_thresh', 0.5,\n",
    "                            \"\"\"thresh for nms\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_detect', 300,\n",
    "                            \"\"\"num of max detect (using in nms)\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fd719279bec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'object/bbox'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'object/label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcrop_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_bboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m '''\n\u001b[1;32m     24\u001b[0m \u001b[0m_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_bboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_bboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Detector/RetinaNet_beom/utils/preprocess.py\u001b[0m in \u001b[0;36mrandom_crop\u001b[0;34m(img, boxes)\u001b[0m\n\u001b[1;32m    442\u001b[0m     '''\n\u001b[1;32m    443\u001b[0m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m#area = img.size[0] * img.size[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clova1/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       raise TypeError(\n\u001b[0;32m--> 431\u001b[0;31m           \u001b[0;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    433\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "\n",
    "net = RetinaNet(\"resnet50\")\n",
    "\n",
    "input_features = []\n",
    "print(\"2\")\n",
    "InputFeatures = collections.namedtuple('InputFeatures', ('image', 'loc', 'cls'))\n",
    "input_producer = InputProducer()\n",
    "\n",
    "split_name = 'train_2000'\n",
    "print(\"3\")\n",
    "dataset = input_producer.get_split(split_name, '/root/DB/VOC/VOC2012/tfrecord/')\n",
    "print(\"4\")\n",
    "provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "                dataset,\n",
    "                num_readers=4,\n",
    "                common_queue_capacity=80,\n",
    "                common_queue_min=40,\n",
    "                shuffle=True)\n",
    "print(\"5\")\n",
    "_images, _bboxes, _labels = provider.get(['image', 'object/bbox', 'object/label'])\n",
    "\n",
    "crop_img, crop_box = random_crop(_images, _bboxes)\n",
    "'''\n",
    "_images, _bboxes = net.preprocess_image(_images, _bboxes)\n",
    "\n",
    "_bboxes, _labels = self.encode(_bboxes, _labels)\n",
    "\n",
    "total_anchor = net._get_anchor_boxes()\n",
    "total_anchor = change_box_order(total_anchor, \"xywh2xyxy\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "VOC = {1 : \"motorbike\", 2 : \"car\", 3 : \"person\", 4 : \"bus\", 5 : \"bird\", 6 : \"horse\", 7 : \"bicycle\", 8 : \"chair\", 9 : \"aeroplane\", 10 : \"diningtable\", 11 : \"pottedplant\", 12 : \"cat\", 13 : \"dog\", 14 : \"boat\", 15 : \"sheep\", 16 : \"sofa\", 17 : \"cow\", 18 : \"bottle\", 19 : \"tvmonitor\", 20 : \"train\"}\n",
    "\n",
    "def draw_boxes(img, bboxes, classes):\n",
    "    if len(bboxes) == 0:\n",
    "        return img\n",
    "\n",
    "    height, width, _ = img.shape\n",
    "    image = Image.fromarray(img)\n",
    "    font = ImageFont.truetype(\n",
    "        font='/root/FiraMono-Medium.otf',\n",
    "        size=np.floor(3e-2 * image.size[1] + 0.4).astype('int32'))\n",
    "\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for box, category in zip(bboxes, classes):\n",
    "        y1, x1, y2, x2 = [int(i) for i in box]\n",
    "        #x1, y1, x2, y2 = [int(i) for i in box]\n",
    "        \n",
    "        p1 = (x1, y1)\n",
    "        p2 = (x2, y2)\n",
    "\n",
    "        label = '{} '.format(category.title())\n",
    "        label_size = draw.textsize(label)\n",
    "        text_origin = np.array([p1[0], p1[1] - label_size[1]])\n",
    "\n",
    "        color = np.array([0, 255, 0])\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [p1[0] + i, p1[1] + i, p2[0] - i, p2[1] - i],\n",
    "                outline=tuple(color))\n",
    "\n",
    "        draw.rectangle(\n",
    "            [tuple(text_origin),\n",
    "             tuple(text_origin + label_size)],\n",
    "            fill=tuple(color))\n",
    "\n",
    "        draw.text(\n",
    "            tuple(text_origin),\n",
    "            label, fill=(0, 0, 0),\n",
    "            font=font)\n",
    "\n",
    "    del draw\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dimension(input):\n",
    "    out = []\n",
    "    for i in input:\n",
    "        out.append(np.expand_dims(i, 0))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                           tf.local_variables_initializer())\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    with slim.queues.QueueRunners(sess):\n",
    "        for i in range(10):\n",
    "            #np_image, np_bbox, np_label = sess.run([image, bboxes, labels])\n",
    "            #np_loc, np_cls = sess.run([loc, cls])\n",
    "            #np_anchor = sess.run(total_anchor)\n",
    "            \n",
    "            #np_image, np_bbox, np_label = sess.run([image2, boxes2, _labels])\n",
    "            #np_image, np_bbox, np_label = expand_dimension([np_image, np_bbox, np_label])\n",
    "            \n",
    "            np_image, np_bbox, np_label = sess.run([crop_img, crop_box, _labels])\n",
    "            \n",
    "            #h, w, _ = np_image.shape\n",
    "            \n",
    "            #np_image = np.array(np_image, np.uint8)\n",
    "            \n",
    "            np_class = [VOC[l] for l in np_label[0]]\n",
    "            \n",
    "            figure(figsize = (12,12))\n",
    "            print(np_image[0].shape, np_bbox[0], np_class)\n",
    "            img = cv2.resize(np_image[0], (608, 608))\n",
    "            img = draw_boxes(img, np_bbox[0]*608, np_class)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            continue\n",
    "            \n",
    "            np_label = [VOC[idx] for idx in np_label]\n",
    "            print(np_image.shape, np_label)\n",
    "            \n",
    "            #np_bbox = (np_bbox * [w, h, w, h]) #.astype(np.int32)\n",
    "            \n",
    "            '''\n",
    "            for i, box in enumerate(np_anchor):\n",
    "                box = (box / 608) * 1200\n",
    "                print(i+1, box)\n",
    "                s_img = img.copy()\n",
    "                s_img = cv2.rectangle(s_img, (box[0], box[1]), (box[2], box[3]), (0,255,0), 2)\n",
    "            \n",
    "                figure(figsize = (12,12))\n",
    "                plt.imshow(s_img)\n",
    "                plt.show()\n",
    "                if i == 30:\n",
    "                    break\n",
    "            '''\n",
    "\n",
    "            img = draw_boxes(np_image, np_bbox, np_label)\n",
    "            figure(figsize = (12,12))\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
